{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "LGy9X9qgUbUW"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "# Downloading dataset from url\n",
        "url = \"https://gist.githubusercontent.com/farhaan-settyl/ecf9c1e7ab7374f18e4400b7a3d2a161/raw/f94652f217eeca83e36dab9d08727caf79ebdecf/dataset.json\"\n",
        "filename = \"dataset.json\"\n",
        "urlretrieve(url, filename)\n",
        "\n",
        "# Convert JSON file to CSV\n",
        "def json_to_csv(json_file, csv_file):\n",
        "    with open(json_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Assuming JSON data is a list of dictionaries\n",
        "    keys = data[0].keys() if data else []\n",
        "\n",
        "    # write into a CSV file.\n",
        "    with open(csv_file, 'w', newline='') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=keys)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(data)\n",
        "\n",
        "json_path = \"./dataset.json\"\n",
        "csv_path = \"./dataset.csv\"\n",
        "\n",
        "# Example usage\n",
        "json_to_csv(json_path, csv_path)\n",
        "\n",
        "# Read CSV file into pandas DataFrame\n",
        "df = pd.read_csv(csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get column names from the DataFrame\n",
        "column_names = df.columns.tolist()\n",
        "\n",
        "# Print the column names\n",
        "print(column_names)\n"
      ],
      "metadata": {
        "id": "tyOCSyX8VfYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934777f2-de5f-4fd6-b751-f96dd65c2ec8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['externalStatus', 'internalStatus']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique classes from the \"internalStatus\" column\n",
        "unique_classes = df[\"internalStatus\"].unique()\n",
        "\n",
        "# Print the unique classes\n",
        "for cl in unique_classes:\n",
        "  print(cl)\n",
        "\n",
        "print(len(unique_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mWBVJSSH204",
        "outputId": "1a07e518-b584-4e30-f7de-2cb2ef530760"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Port Out\n",
            "Inbound Terminal\n",
            "Port In\n",
            "Departure\n",
            "Arrival\n",
            "Gate In\n",
            "Loaded on Vessel\n",
            "Gate Out\n",
            "On Rail\n",
            "Off Rail\n",
            "Empty Return\n",
            "In-transit\n",
            "Outbound Terminal\n",
            "Empty Container Released\n",
            "Unloaded on Vessel\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Read the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv(\"/content/dataset.csv\")\n",
        "\n",
        "# Select the columns with text data\n",
        "text_columns = [\"externalStatus\", \"internalStatus\"]\n",
        "\n",
        "# Remove rows with missing values in the selected columns\n",
        "df = df.dropna(subset=text_columns)\n",
        "\n",
        "# Convert all text data to lowercase\n",
        "for column in text_columns:\n",
        "  df[column] = df[column].str.lower()\n",
        "\n",
        "# Remove punctuation from the text data\n",
        "for column in text_columns:\n",
        "  df[column] = df[column].str.replace('[^\\w\\s]', '')\n",
        "\n",
        "# Remove stop words from the text data\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "for column in text_columns:\n",
        "  df[column] = df[column].apply(\n",
        "      lambda x: ' '.join([word for word in x.split() if word not in stop_words])\n",
        "      )\n",
        "\n",
        "# Print the preprocessed data\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "-YO7W71EWLQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4d27d1-084f-4dcd-ed99-bbb3e4c06908"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         externalStatus  \\\n",
            "0                                                  port   \n",
            "1                                              terminal   \n",
            "2                                                  port   \n",
            "3     vessel departure first pol (vessel name : tian...   \n",
            "4     vessel arrival final pod (vessel name : tian f...   \n",
            "...                                                 ...   \n",
            "1217                                 import loaded rail   \n",
            "1218                          full transshipment loaded   \n",
            "1219                          full transshipment loaded   \n",
            "1220                               export loaded vessel   \n",
            "1221                                      empty shipper   \n",
            "\n",
            "                internalStatus  \n",
            "0                         port  \n",
            "1             inbound terminal  \n",
            "2                         port  \n",
            "3                    departure  \n",
            "4                      arrival  \n",
            "...                        ...  \n",
            "1217             loaded vessel  \n",
            "1218             loaded vessel  \n",
            "1219             loaded vessel  \n",
            "1220             loaded vessel  \n",
            "1221  empty container released  \n",
            "\n",
            "[1222 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Create a CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer to the\n",
        "# \"externalStatus\" column\n",
        "vectorizer.fit(df[\"externalStatus\"])\n",
        "\n",
        "# Transform the \"externalStatus\" column\n",
        "# into a bag-of-words representation\n",
        "external_status_bow = vectorizer.transform(df[\"externalStatus\"])\n",
        "\n",
        "# Print the bag-of-words representation\n",
        "print(external_status_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZbDVN9FwseP",
        "outputId": "dfdb4837-a335-4387-d7a6-59a85fa3168a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 106)\t1\n",
            "  (1, 121)\t1\n",
            "  (2, 106)\t1\n",
            "  (3, 48)\t1\n",
            "  (3, 62)\t1\n",
            "  (3, 63)\t1\n",
            "  (3, 70)\t1\n",
            "  (3, 90)\t1\n",
            "  (3, 105)\t1\n",
            "  (3, 122)\t1\n",
            "  (3, 134)\t2\n",
            "  (4, 30)\t1\n",
            "  (4, 61)\t1\n",
            "  (4, 63)\t1\n",
            "  (4, 70)\t1\n",
            "  (4, 90)\t1\n",
            "  (4, 104)\t1\n",
            "  (4, 122)\t1\n",
            "  (4, 134)\t2\n",
            "  (5, 47)\t1\n",
            "  (6, 66)\t1\n",
            "  (7, 11)\t1\n",
            "  (7, 80)\t1\n",
            "  (7, 83)\t1\n",
            "  (7, 115)\t1\n",
            "  :\t:\n",
            "  (1213, 64)\t1\n",
            "  (1213, 81)\t1\n",
            "  (1213, 127)\t1\n",
            "  (1214, 60)\t1\n",
            "  (1214, 81)\t1\n",
            "  (1214, 134)\t1\n",
            "  (1215, 56)\t1\n",
            "  (1215, 116)\t1\n",
            "  (1216, 73)\t1\n",
            "  (1216, 109)\t1\n",
            "  (1216, 129)\t1\n",
            "  (1217, 73)\t1\n",
            "  (1217, 81)\t1\n",
            "  (1217, 109)\t1\n",
            "  (1218, 64)\t1\n",
            "  (1218, 81)\t1\n",
            "  (1218, 127)\t1\n",
            "  (1219, 64)\t1\n",
            "  (1219, 81)\t1\n",
            "  (1219, 127)\t1\n",
            "  (1220, 60)\t1\n",
            "  (1220, 81)\t1\n",
            "  (1220, 134)\t1\n",
            "  (1221, 56)\t1\n",
            "  (1221, 116)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tsize = 0.2"
      ],
      "metadata": {
        "id": "dil7_LgEfEOu"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier as rfclass\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    external_status_bow,\n",
        "    df[\"internalStatus\"],\n",
        "    test_size=tsize\n",
        "    )\n",
        "\n",
        "# Create a Random Forest model\n",
        "model = rfclass(n_estimators=10)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train.toarray(), y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = model.predict(X_test.toarray())\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NedZ2HtbnnWa",
        "outputId": "a87a3439-f89a-401a-df44-e126926de6e1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9959183673469387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    external_status_bow,\n",
        "    df[\"internalStatus\"],\n",
        "    test_size=tsize\n",
        "    )\n",
        "\n",
        "# Create a Gaussian Naive Bayes model\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train.toarray(), y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = model.predict(X_test.toarray())\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbYXPxt3wSfM",
        "outputId": "d1a24b54-1eb7-4abf-f5e0-e5b33b3a5f48"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9836734693877551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier as dtclass\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    external_status_bow,\n",
        "    df[\"internalStatus\"],\n",
        "    test_size=tsize\n",
        "    )\n",
        "\n",
        "# Create a Decision Tree Model\n",
        "model = dtclass(criterion=\"log_loss\")\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train.toarray(), y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = model.predict(X_test.toarray())\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(accuracy)\n",
        "\n",
        "import graphviz\n",
        "dot_data = tree.export_graphviz(model, out_file=None)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"port\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d8b1834e-e257-40b9-f728-71ce83e0e056",
        "id": "CofcU2Cztvh5"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9877551020408163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'port.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e4VaKc9o_ZkE"
      },
      "execution_count": 88,
      "outputs": []
    }
  ]
}